# api_request/airflow/dags/dbt_orchestrator.py
from __future__ import annotations
import os
from datetime import datetime

from airflow import DAG
from airflow.providers.docker.operators.docker import DockerOperator
from airflow.providers.standard.operators.empty import EmptyOperator
from docker.types import Mount  # üîë d√πng Mount thay cho volumes

DBT_IMAGE = os.getenv("DBT_IMAGE", "ghcr.io/dbt-labs/dbt-postgres:1.9.latest")
DBT_PROJECT_DIR = os.getenv("DBT_PROJECT_DIR", "/usr/app")
DBT_PROFILES_DIR = os.getenv("DBT_PROFILES_DIR", "/root/.dbt")  # l√† TH∆Ø M·ª§C
DBT_TARGET = os.getenv("DBT_TARGET", "dev")
DBT_THREADS = os.getenv("DBT_THREADS", "4")

# Paths tr√™n HOST (m√°y ch·∫°y Docker daemon)
HOST_PROJECT = os.getenv("AIRFLOW_DBT_PROJECT_HOST_PATH", "/opt/airflow/dbt/my_project")
# Khuy·∫øn ngh·ªã: ƒë·ªÉ s·∫µn c·∫£ folder .dbt ch·ª©a profiles.yml
HOST_PROFILES_DIR = os.getenv("AIRFLOW_DBT_PROFILES_DIR_HOST_PATH", "/opt/airflow/.dbt")
# N·∫øu b·∫°n ch·ªâ c√≥ 1 file, c≈©ng ƒë∆∞·ª£c, xem Option B ph√≠a d∆∞·ªõi

COMMON_KWARGS = dict(
    image=DBT_IMAGE,
    auto_remove="success",
    tty=True,
    docker_url=os.getenv("DOCKER_URL", "unix://var/run/docker.sock"),
    network_mode=os.getenv("DOCKER_NETWORK", "api_request_my-network"),
    environment={
        "DBT_PROFILES_DIR": DBT_PROFILES_DIR,
        "DBT_TARGET": DBT_TARGET,
        "DBT_THREADS": DBT_THREADS,
    },
    # ‚ùó mounts thay cho volumes
    mounts=[
        # Project: bind c·∫£ folder code v√†o /usr/app
        Mount(source=HOST_PROJECT, target=DBT_PROJECT_DIR, type="bind", read_only=False),

        # Option A (khuy·∫øn ngh·ªã): bind c·∫£ th∆∞ m·ª•c .dbt (ch·ª©a profiles.yml)
        Mount(source=HOST_PROFILES_DIR, target=DBT_PROFILES_DIR, type="bind", read_only=True),
    ],
    working_dir=DBT_PROJECT_DIR,
    mount_tmp_dir=False,  # tr√°nh mount /tmp m·∫∑c ƒë·ªãnh c·ªßa operator n·∫øu kh√¥ng c·∫ßn
)

with DAG(
    dag_id="weather_dbt_orchestrator",
    description="DAG to orchestrate weather data fetching and dbt pipeline",
    start_date=datetime(2023, 10, 1),
    schedule=None,
    catchup=False,
    tags=["dbt"],
) as dag:
    dbt_run = DockerOperator(
        task_id="transform_data_task",
        command=f"run --target {DBT_TARGET}",  # image entrypoint already invokes `dbt`
        **COMMON_KWARGS,
    )
